{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Importuri necesare",
   "id": "84d1ce926da3afb7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical"
   ],
   "id": "4ab5150728261772",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Verificam dimensiunile pozelor (daca este nevoie de resize la aceasi dimensiune)",
   "id": "6692224f5f0d02b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dimensiuni = {}\n",
    "path = \"data/train\"\n",
    "for file in os.listdir(path):\n",
    "    if file.lower().endswith('.png'):\n",
    "        img_path = os.path.join(path, file)\n",
    "        with Image.open(img_path) as img:\n",
    "            dimensiuni[file] = img.size\n",
    "\n",
    "dimensiuni_unice = set(dimensiuni.values())\n",
    "\n",
    "if len(dimensiuni_unice) == 1:\n",
    "    print(\"Toate pozele au aceasi dimensiune: \", dimensiuni_unice.pop())\n",
    "\n",
    "else:\n",
    "    print(\"Dimensiunile gasite sunt: \")\n",
    "    for dimensiune in dimensiuni_unice:\n",
    "        print(dimensiune)\n"
   ],
   "id": "ad001a2e0c01b553",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Verificam daca exista poze alb negru",
   "id": "53dea05dbc0013ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def veirifcare_alb_negru(image_path):\n",
    "    with Image.open(image_path) as poza:\n",
    "        if poza.mode in ('L', '1'):\n",
    "            return True\n",
    "        if poza.mode == 'RGB':\n",
    "            poza_np = np.array(poza)\n",
    "            return np.all(poza_np[:,:,0] == poza_np[:,:,1]) and np.all(poza_np[:,:,1] == poza_np[:,:,2])\n",
    "\n",
    "def loader_poze(path):\n",
    "    cnt = 0\n",
    "    for fisier in os.listdir(path):\n",
    "        if fisier.lower().endswith('.png'):\n",
    "            fisier_path = os.path.join (path, fisier)\n",
    "            if veirifcare_alb_negru(fisier_path):\n",
    "                print(f'{fisier} este alb negru.')\n",
    "                cnt += 1\n",
    "    if cnt == 0:\n",
    "         print(\"Nu exista outliers, toate pozele sunt color\")\n",
    "\n",
    "\n",
    "path = 'data/train'\n",
    "loader_poze(path)"
   ],
   "id": "578d495c9f07c9ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Calculam media si deviatia standard",
   "id": "d0bf908445a78270"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def media_si_deviatia_standard(folder_path):\n",
    "    sum_culori = np.zeros(3, dtype=np.float64)\n",
    "    sum_culori_la_patrat = np.zeros(3, dtype=np.float64)\n",
    "    nr_pixeli = 0\n",
    "\n",
    "    for nume_fisier in os.listdir(folder_path):\n",
    "        imagine = cv2.imread(os.path.join(folder_path, nume_fisier))\n",
    "\n",
    "        if imagine is not None:\n",
    "            poza_in_float = imagine.astype(np.float64)\n",
    "\n",
    "            sum_culori += np.sum(poza_in_float, axis=(0, 1))\n",
    "            sum_culori_la_patrat += np.sum(np.square(poza_in_float), axis=(0, 1))\n",
    "            nr_pixeli += poza_in_float.shape[0] * poza_in_float.shape[1]\n",
    "\n",
    "    media = sum_culori / nr_pixeli\n",
    "    deviatia_standard = np.sqrt((sum_culori_la_patrat / nr_pixeli) - np.square(media))\n",
    "\n",
    "    return media, deviatia_standard\n",
    "\n",
    "path = \"data/train\"\n",
    "\n",
    "media, deviatia_standard = media_si_deviatia_standard(path)\n",
    "\n",
    "print(media_si_deviatia_standard(path))"
   ],
   "id": "eb559ad54aa98b4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Normalizam pozele pe baza mediei si a deviatiei standard",
   "id": "531efd1888042e26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "media = np.array([105.74, 117.83, 121.29])\n",
    "deviatia_standard = np.array([71.68, 69.16, 69.32])\n",
    "\n",
    "def normalizare(imagine, media, deviatia_standard):\n",
    "    imagine_float = imagine.astype(np.float64)\n",
    "    normalizata = (imagine_float - media) / deviatia_standard\n",
    "    return normalizata\n",
    "\n",
    "def procesare(path, path_iesire, media, deviatia_standard):\n",
    "    for imagine in os.listdir(path):\n",
    "        imagine_full = cv2.imread(os.path.join(path, path_iesire))\n",
    "        normalizata = normalizare(imagine_full, media, deviatia_standard)\n",
    "\n",
    "        fisier_output = os.path.splitext(file)[0] + \".npy\"\n",
    "        path_output = os.path.join(path_iesire, fisier_output)\n",
    "        np.save(path_output, normalizata)\n",
    "\n",
    "folder = \"data/test\"\n",
    "path_iesire = \"data/test_normalised\"\n",
    "\n",
    "procesare(folder, path_iesire, media, deviatia_standard)"
   ],
   "id": "6ecc563c7669a88",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Incarcam pozele normalizate in format .npy pentru antrenare si teste",
   "id": "95a7714c14102064"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def data_loader(csv_path, img_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        image_id = str(row['image_id']) + \".npy\"\n",
    "        label = row['label']\n",
    "\n",
    "        image_path = os.path.join(img_path, image_id)\n",
    "\n",
    "        image = np.load(image_path)\n",
    "\n",
    "        image = image.flatten()\n",
    "\n",
    "        images.append(image)\n",
    "\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "img_path = \"data/train_normalised\"\n",
    "\n",
    "csv_path = \"data/train.csv\"\n",
    "\n",
    "images_train, labels_train = data_loader(csv_path, img_path)\n",
    "\n",
    "img_path = \"data/validation_normalised\"\n",
    "\n",
    "csv_path = \"data/validation.csv\"\n",
    "\n",
    "images_validation, labels_validation = data_loader(csv_path, img_path)"
   ],
   "id": "5be6badd396ddb0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Incarcam pozele NEnormalizate in format .png pentru teste",
   "id": "9bea631815d8f456"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def data_loader(csv_path, img_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for inder, row in df.iterrows():\n",
    "        image_id = str(row['image_id']) + \".png\"\n",
    "        label = row['label']\n",
    "\n",
    "        image_path = os.path.join(img_path, image_id)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        image = image.flatten()\n",
    "\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "img_path = \"data/train\"\n",
    "\n",
    "csv_path = \"data/train.csv\"\n",
    "\n",
    "images_train, labels_train = data_loader(csv_path, img_path)\n",
    "\n",
    "img_path = \"data/validation\"\n",
    "\n",
    "csv_path = \"data/validation.csv\"\n",
    "\n",
    "images_validation, labels_validation = data_loader(csv_path, img_path)"
   ],
   "id": "6b8caeb0222f1186",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Un model simplu de Random Forest, scopul a fost drept experiment",
   "id": "cd5001cd2cbec74f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "copaceii = RandomForestClassifier(n_estimators = 1000, max_depth = 20, random_state = 42)\n",
    "\n",
    "copaceii.fit(images_train, labels_train)\n",
    "\n",
    "predictions = copaceii.predict(images_validation)\n",
    "\n",
    "print(accuracy_score(labels_validation, predictions))\n",
    "\n",
    "print(confusion_matrix(labels_validation, predictions))"
   ],
   "id": "342cf13a5271758f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Un model simplu de SVM, scopul a fost drept experiment",
   "id": "33f5fa47c2dfa0fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42, probability=False, verbose=True)\n",
    "\n",
    "svm_model.fit(images_train, labels_train)\n",
    "\n",
    "predictions = svm_model.predict(images_validation)\n",
    "\n",
    "accuracy = accuracy_score(labels_validation, predictions)\n",
    "\n",
    "print(accuracy)\n",
    "\n",
    "print(classification_report(labels_validation, accuracy))\n",
    "\n",
    "print(confusion_matrix(labels_validation, accuracy))"
   ],
   "id": "64ba25ba9084cdb0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Ambele rezultate au fost slabe, deci am decis sa folosesc o retea convolutionala.\n",
    "Indiferent de finetuning-ul pe care il faceam la modele nu aveam cum sa cresc rezultatele pe cat imi as fi sperat"
   ],
   "id": "2ed42d5b091ca02a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Aici am definit mai multe variante de retele convolutionale pe care le-am utilizat in timpul experimentelor",
   "id": "f488a19e4aac09f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# acest model a obtinut 91% acuratete (cred) la validare fara data augmentation\n",
    "\n",
    "# retea = models.Sequential([\n",
    "#\n",
    "#     layers.InputLayer(shape=(img_h, img_w, nr_channels)),\n",
    "#\n",
    "#     layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Conv2D(32, (3, 3)), activation = 'relu', padding = 'same'),\n",
    "#     layers.BatchNormalization()\n",
    "#     layers.MaxPooling2D(pool_size = (2, 2)),\n",
    "#     layers.Dropout(0.25),\n",
    "#\n",
    "#     layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.MaxPooling2D(pool_size = (2, 2)),\n",
    "#     layers.Dropout(0.3)\n",
    "#\n",
    "#     layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.MaxPooling2D(pool_size = (2, 2)),\n",
    "#     layers.Dropout(0.35)\n",
    "#\n",
    "#     layers.FLatten(),\n",
    "#     layers.Dense(256, activation = 'relu),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(0.5),\n",
    "#     layers.Dense(nr_classes, activation = 'softmax')\n",
    "# ])\n",
    "\n",
    "# acest model a fost cel mai simplu model incercat\n",
    "# retea = models.Sequential([\n",
    "#\n",
    "#     layers.InputLayer(shape=(img_h, img_w, nr_channels)),\n",
    "#\n",
    "#     layers.Conv2D(16, (5, 5), activation = 'relu', padding = 'same'),\n",
    "#     layers.MaxPooling2D(pool_size = (4, 4)),\n",
    "#     layers.BatchNormalization(),\n",
    "#\n",
    "#     layers.Conv2D(32, (5, 5), activation = 'relu', padding = 'same'),\n",
    "#     layers.MaxPooling2D(pool_size = (4, 4)),\n",
    "#     layers.BatchNormalization(),\n",
    "#\n",
    "#\n",
    "#     layers.FLatten(),\n",
    "#     laters.Dense(32, activation = 'relu'),\n",
    "#     layers.Dropout(0.25)\n",
    "#     layers.Dense(nr_classes, activation = 'softmax')\n",
    "# ])\n",
    "\n",
    "\n",
    "# cel mai puternic model, care facea si cel mai mare overfit fara data augmentation\n",
    "\n",
    "\n",
    "# retea = models.Sequential([\n",
    "#     layers.InputLayer(shape=(img_h, img_w, nr_channels)),\n",
    "#     layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Activation('relu')\n",
    "#     layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Activation('relu')\n",
    "#     layers.MaxPooling2D(pool_size = (3, 3)),\n",
    "#     layers.Dropout(0.3)\n",
    "#\n",
    "#     layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Activation('relu')\n",
    "#     layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Activation('relu')\n",
    "#     layers.MaxPooling2D(pool_size = (2, 2)),\n",
    "#     layers.Dropout(0.3)\n",
    "#\n",
    "#     layers.Conv2D(256, (3, 3), activation = 'relu', padding = 'same'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Activation('relu')\n",
    "#     layers.Conv2D(256, (3, 3), activation = 'relu', padding = 'same'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Activation('relu')\n",
    "#     layers.MaxPooling2D(pool_size = (2, 2)),\n",
    "#     layers.Dropout(0.3)\n",
    "#\n",
    "#     layers.Conv2D(512, (3, 3), activation = 'relu', padding = 'same'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Activation('relu')\n",
    "#     layers.Conv2D(512, (3, 3), activation = 'relu', padding = 'same'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Activation('relu')\n",
    "#     layers.MaxPooling2D(pool_size = (2, 2)),\n",
    "#     layers.Dropout(0.3)\n",
    "#\n",
    "#     layers.Flatten()\n",
    "#     layers.Dense(512, activation  ='relu'\n",
    "#     layers.BatchNormalization()\n",
    "#     layers.Dropout(0.5)\n",
    "#     layers.dense(nr_classes, activation = 'softmax')\n",
    "# ])\n",
    "\n",
    "#\n",
    "# retea = models.Sequential([\n",
    "#     layers.InputLayer(shape=(IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS)),\n",
    "#     layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#     layers.Dropout(0.3),\n",
    "#     layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#     layers.Dropout(0.4),\n",
    "#     layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#     layers.Dropout(0.5),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(128, activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(0.5),\n",
    "#     layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "# ///////////////////////////\n",
    "#\n",
    "#     layers.InputLayer(shape=(IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS)),\n",
    "#     layers.Conv2D(48, (3, 3), padding='same', activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Conv2D(48, (3, 3), padding='same', activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#     layers.Dropout(0.3),\n",
    "#\n",
    "#     layers.Conv2D(96, (3, 3), padding='same', activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Conv2D(96, (3, 3), padding='same', activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#     layers.Dropout(0.4),\n",
    "#\n",
    "#     layers.Conv2D(192, (3, 3), padding='same', activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#     layers.Dropout(0.5),\n",
    "#\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(256, activation='relu'),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(0.5),\n",
    "#     layers.Dense(NUM_CLASSES, activation='softmax')"
   ],
   "id": "a7b5dada96d0ea87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Codul \"complet\" pentru antrenarea unei retele convolutionale cu cateva explicatii unde am considerat ca este cazul",
   "id": "4389139eb8bd7113"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img_h = 100\n",
    "img_w = 100\n",
    "nr_channels = 3\n",
    "nr_classes = 5\n",
    "\n",
    "batches = 32\n",
    "epochs = 10 #in alte iteratii o sa ajunga si 150-200 depinde de retea\n",
    "\n",
    "# aici puteam modifica \"greutatile\" de asemene, dar deoarece setul nostru de date este perfect echilibrat, nu a fost necesar\n",
    "# avem 12500 de poze, si 2500 pentru fiecare eticheta\n",
    "\n",
    "# aplatizam imaginile pentru ca putem folosi straturi dense (nu mereu dar e bine sa ramana aici)\n",
    "images_train_flat = images_train.reshape(-1, img_h, img_w, nr_channels)\n",
    "images_validation_flat = images_validation.reshape(-1, img_h, img_w, nr_channels)\n",
    "\n",
    "# folosim one hot encodingla label-uri pentru a prezenta probabilitatea de a alege o clasa\n",
    "labels_train_hot = to_categorical(labels_train, num_classes = nr_classes)\n",
    "labels_validation_hot = to_categorical(labels_validation, num_classes = nr_classes)\n",
    "\n",
    "# pentru variant\n",
    "retea = models.Sequential([\n",
    "\n",
    "    layers.InputLayer(shape=(img_h, img_w, nr_channels)),\n",
    "\n",
    "    # x = layers.RandomFlip(\"horizontal\", name=\"random_flip\")(inputs)\n",
    "    # x = layers.RandomRotation(0.05, name=\"random_rotation\")(x)\n",
    "    # x = layers.RandomZoom(0.05, name=\"random_zoom\")(x)\n",
    "\n",
    "    # cateva modetode de data augmentation care nu au fost de succes\n",
    "\n",
    "\n",
    "    layers.Conv2D(24, (7, 7), activation = 'relu', padding = 'same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size = (2, 2)),\n",
    "\n",
    "    layers.Conv2D(48, (5, 5), activation = 'relu', padding = 'same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size = (2, 2)),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size = (2, 2)),\n",
    "\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.4),\n",
    "\n",
    "    layers.Dense(nr_classes, activation = 'softmax')\n",
    "])\n",
    "\n",
    "retea.summary()\n",
    "\n",
    "retea.compile(optimizer = 'adam', #exista si varianta adamh care e posibil sa fie mai buna dar nu am experimentat cu aceasta\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# definim callbacks si parametrii acestora\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath = 'model.keras',\n",
    "    save_weights_only = False,\n",
    "    monitor = 'val_accuracy',\n",
    "    mode = 'max',\n",
    "    save_best_only = True,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "stopping = EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    patience = 15,\n",
    "    verbose = 1,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "reduce_learning = ReduceLROnPlateau(\n",
    "    monitor = 'val_loss',\n",
    "    factor = 0.5,\n",
    "    patience = 7,\n",
    "    verbose = 1,\n",
    "    min_lr = 0.0001 #posibil sa fie prea mare si sa trebuiasca sa il scad\n",
    ")\n",
    "\n",
    "list_of_callbacks = [checkpoint, stopping, reduce_learning]\n",
    "\n",
    "history = retea.fit(images_train_flat, labels_train_hot,\n",
    "                    validation_data = (images_validation_flat, labels_validation_hot),\n",
    "                    epochs = epochs,\n",
    "                    batch_size = batches,\n",
    "                    callbacks = list_of_callbacks\n",
    "                    )\n",
    "\n",
    "model_x = models.load_model('model.keras')\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "278b5bb9e3377e5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dupa mai multe teste, am ajuns la concluzia ca primele 3 clase sunt confundate cu cea de a 4-a clasa, deci am decis sa mai fac cateva teste. Primul test a fost de a verifica canalele de culoare RGB, dupa HSV si dupa LAB pentru a incerca sa inteleg culorile. Motivul pentru care am luat aceasta decizie a fost cauzat de performanta ridicata a Random Forest (70%) avand in vedere ca se facea doar pe pixeli individual.",
   "id": "a93e5defb61a6fdb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "medie_poze = []\n",
    "\n",
    "# calculam media pentru fiecare clasa\n",
    "for i in range(nr_classes):\n",
    "    clasa_poze = images_train_flat[labels_train == i]\n",
    "    medie_poza = np.mean(clasa_poze, axis = 0)\n",
    "    medie_poze.append(medie_poza)\n",
    "\n",
    "out, ax = plt.subplots(1, nr_classes, figsize = (16, 5))\n",
    "\n",
    "\n",
    "for i in range(nr_classes):\n",
    "    afis = medie_poze[i]\n",
    "\n",
    "\n",
    "    # a trebuit sa realizam aceasta normalizare, deoarece nu erau evidentiate culorile atat de bine\n",
    "    val_min, val_max = afis.min(), afis.max()\n",
    "    if val_max > val_min:\n",
    "        afis = (afis - val_min) / (val_max - val_min)\n",
    "\n",
    "    ax[i].imshow(afis)\n",
    "    ax[i].set_title(i)\n",
    "\n",
    "\n",
    "# la afisare, avem cate o poza pentru fiecare clasa\n",
    "plt.suptitle('Canale RGB', fontsize = 16)\n",
    "plt.show()"
   ],
   "id": "5565d16900867310",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![RGB](rgb.png)",
   "id": "963a7dde26afa698"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def medie(poze):\n",
    "    if len(poze) == 0:\n",
    "        return np.zeros((img_h, img_w, nr_channels))\n",
    "\n",
    "    # separarea canalelor H, S si V\n",
    "    hue = poze[:, :, :, 0]\n",
    "    saturation = poze[:, :, :, 1]\n",
    "    values = poze[:, :, :, 2]\n",
    "\n",
    "    # calculam media\n",
    "\n",
    "    rad_hue = hue * 2 * np.pi #convertim de la 0-1 la radiani 0-2*pi\n",
    "\n",
    "    # convertim in coordonate carteziene\n",
    "    x = np.cos(rad_hue)\n",
    "    y = np.sin(rad_hue)\n",
    "\n",
    "    # calculam media verctorilor\n",
    "    mean_x = np.mean(x, axis = 0)\n",
    "    mean_y = np.mean(y, axis = 0)\n",
    "\n",
    "    # convertim media la radiani\n",
    "    mean_hue_rad = np.arctan2(mean_y, mean_x)\n",
    "\n",
    "    # convertim inapoi la 0-1\n",
    "    mean_hue = (mean_hue_rad % (2 * np.pi)) / (2 * np.pi)\n",
    "\n",
    "    # calculam media pentru saturation si value\n",
    "    mean_saturation = np.mean(saturation, axis = 0)\n",
    "    mean_value = np.mean(values, axis = 0)\n",
    "\n",
    "    # combinam datele\n",
    "    mean_hsv_image = np.stack([mean_hue, mean_saturation, mean_value], axis = -1)\n",
    "\n",
    "    return mean_hsv_image\n",
    "\n",
    "mean_hsv_images = []\n",
    "\n",
    "for i in range(nr_classes):\n",
    "    class_hsv_images = images_train_flat[labels_train == i]\n",
    "    mean_hsv = medie(class_hsv_images)\n",
    "    mean_hsv_images.append(mean_hsv)\n",
    "\n",
    "# transformam pozele rezultatele din hsv in rgb pentru afisare\n",
    "mean_rgb = [tf.image.hsv_to_rgb(img).numpy() for img in mean_hsv_images]\n",
    "\n",
    "out, ax = plt.subplots(1, nr_classes, figsize = (16, 5))\n",
    "\n",
    "\n",
    "for i in range(nr_classes):\n",
    "    afis = mean_rgb[i]\n",
    "\n",
    "    val_min, val_max = afis.min(), afis.max()\n",
    "    if val_max > val_min:\n",
    "        afis = (afis - val_min) / (val_max - val_min)\n",
    "\n",
    "    ax[i].imshow(afis)\n",
    "    ax[i].set_title(i)\n",
    "\n",
    "plt.suptitle('HSV', fontsize=16)\n",
    "plt.show()"
   ],
   "id": "932ced345be3e3ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![HSV](hsv.png)",
   "id": "a5e3662ca2b51133"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2hsv\n",
    "\n",
    "def medie_lab_in_rgb(images):\n",
    "\n",
    "    lab_images = np.array([rgb2lab(img) for img in images])\n",
    "    if len(images) == 0:\n",
    "        return np.zeros((100, 100, 3))\n",
    "    mean_lab = np.mean(lab_images, axis = 0)\n",
    "    return lab2rgb(mean_lab)\n",
    "\n",
    "def medie_canal(images, color_space = 'hsv', channel_id = 0):\n",
    "\n",
    "    if len(images) == 0:\n",
    "        return np.zeros((100,100))\n",
    "\n",
    "    if color_space == 'hsv' :\n",
    "        converted_images = np.array([rgb2hsv(img) for img in images])\n",
    "\n",
    "    elif color_space == 'lab':\n",
    "        converted_images = np.array([rgb2lab(img) for img in images])\n",
    "\n",
    "    else:\n",
    "        return np.zeros((100,100))\n",
    "\n",
    "    return np.mean(converted_images[:, :, :, channel_id], axis = 0)\n",
    "\n",
    "med_lab_rgb_img = []\n",
    "med_hue_channels = []\n",
    "med_a_star_channels = []\n",
    "med_b_star_channels = []\n",
    "\n",
    "for i in range(nr_classes):\n",
    "    class_images = images_train_flat[labels_train == i]\n",
    "\n",
    "    med_lab_rgb_img.append(medie_lab_in_rgb(class_images))\n",
    "    med_hue_channels.append(medie_canal(class_images, 'hsv', 0))\n",
    "    med_a_star_channels.append(medie_canal(class_images, 'lab', 1))\n",
    "    med_b_star_channels.append(medie_canal(class_images, 'lab', 2))\n",
    "\n",
    "out, ax = plt.subplots(4, nr_classes, figsize = (16, 12))\n",
    "out.suptitle('LAB')\n",
    "\n",
    "\n",
    "data = [\n",
    "    med_lab_rgb_img,\n",
    "    med_hue_channels,\n",
    "    med_a_star_channels,\n",
    "    med_b_star_channels\n",
    "]\n",
    "\n",
    "data_n = [None, 'hsv', 'coolwarm', 'coolwarm']\n",
    "\n",
    "for r, rr in enumerate(data):\n",
    "    for col in range(nr_classes):\n",
    "        afis = rr[col]\n",
    "        val_min, val_max = afis.min(), afis.max()\n",
    "        if val_max > val_min:\n",
    "            afis = (afis - val_min) / (val_max - val_min)\n",
    "\n",
    "        ax[r, col].imshow(afis, cmap = data_n[r])\n",
    "        ax[r, col].axis('off')\n",
    "\n",
    "        if r == 0:\n",
    "            ax[r, col].set_title(col)\n",
    "\n",
    "plt.show()"
   ],
   "id": "1e5232f60c4c9f39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![LAB](lab.png)",
   "id": "be9529be4fb1b98d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Am incercat sa antrenez un model de XGBoost pe baza histogramelor de culori, dar rezultatele au lasat de dorit",
   "id": "a0c56b3b8bcc0840"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def histograme(image_set, n_bins = 32):\n",
    "\n",
    "    histograms = []\n",
    "\n",
    "    for img in image_set:\n",
    "        hist_features = np.concatenate([\n",
    "            np.histogram(img[:, :, 0], bins = n_bins, range = [0,256]) [0],\n",
    "            np.histogram(img[:, :, 1], bins = n_bins, range = [0,256]) [0],\n",
    "            np.histogram(img[:, :, 2], bins = n_bins, range = [0,256]) [0],\n",
    "        ])\n",
    "\n",
    "        if hist_features.sum() > 0:\n",
    "            hist_features = hist_features / hist_features.sum()\n",
    "\n",
    "        histograms.append(hist_features)\n",
    "    return np.array(histograms)\n",
    "\n",
    "images_train_reshaped = images_train_flat.reshape(-1, 100, 100, 3)\n",
    "\n",
    "train_hist = histograme(images_train_reshaped)\n",
    "\n",
    "images_validation_reshaped = images_validation_flat.reshape(-1, 100, 100, 3)\n",
    "\n",
    "validation_hist = histograme(images_validation_reshaped)\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    objective = 'multi:softmax',\n",
    "    num_class = len(np.unique(labels_train)),\n",
    "    n_estimators = 350,\n",
    "    learning_rate = 0.15,\n",
    "    max_depth = 7,\n",
    "    use_label_encoder = False,\n",
    "    eval_metric = 'mlogloss'\n",
    ")\n",
    "\n",
    "model.fit(train_hist, labels_train)\n",
    "\n",
    "predictions = model.predict(validation_hist)\n",
    "\n",
    "print(classification_report(labels_validation, predictions))\n",
    "\n",
    "matrice = confusion_matrix(labels_validation, predictions)\n",
    "plt.show"
   ],
   "id": "16d20c8ef2d615f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, nr_classes, figsize=(15, 4))\n",
    "\n",
    "for i in range(nr_classes):\n",
    "    # Calculează imaginea medie pentru clasa curentă\n",
    "    mean_image = np.mean(images_train[labels_train == i], axis=0)\n",
    "\n",
    "    # Normalizează imaginea medie la intervalul [0, 1] pentru afișare\n",
    "    min_val, max_val = mean_image.min(), mean_image.max()\n",
    "    if (max_val - min_val) > 0:\n",
    "        normalized_image = (mean_image - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        normalized_image = mean_image\n",
    "\n",
    "    # Afișează imaginea normalizată\n",
    "    axes[i].imshow(normalized_image)\n",
    "    axes[i].set_title(i)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "a49ebc314b4325ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Codul pentru definirea functiei de cutout (data augmentation)",
   "id": "4ac3fa7f017ec86a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Am revenit la reteaua convolutionala si am incercat o metoda noua de Data Augmentation, aceea fiind cutout. Dupa ce am experimentat cu aceasta am descoperit pe internet si cutmix, metoda cu care am obtinut rezultate si mai bune",
   "id": "70c8687cd3ff1816"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def cutout(image):\n",
    "    h = tf.cast(img_h * 0.25, dtype = tf.int32)\n",
    "    w = tf.cast(img_w * 0.25, dtype = tf.int32)\n",
    "\n",
    "    cy = tf.random.uniform([], 0, img_h, dtype = tf.int32)\n",
    "    cx = tf.random.uniform([], 0, img_w, dtype = tf.int32)\n",
    "\n",
    "    y1 = tf.clip_by_value(cy - h // 2, 0, img_h)\n",
    "    y2 = tf.clip_by_value(cy + h // 2, 0, img_h)\n",
    "    x1 = tf.clip_by_value(cx - w // 2, 0, img_h)\n",
    "    x2 = tf.clip_by_value(cx - w // 2, 0, img_h)\n",
    "\n",
    "    mask = tf.ones_like(image)\n",
    "    padding = [[y1, img_h - y2], [x1, img_w - x2], [0, 0]]\n",
    "    cutout_region = tf.zeros([y2 - y1, x2 - x1, nr_channels])\n",
    "\n",
    "    mask_cutout_part = tf.pad(cutout_region, padding, \"CONSTANT\", constant_values = 1)\n",
    "    mask = mask - 1,(1 - mask_cutout_part)\n",
    "\n",
    "    return image*mask\n",
    "\n",
    "# apelul se face prin adaugarea urmatoarei functii lambda la layer\n",
    "#\n",
    "# layers.Lambda(lambda x: tf.map_fn(custom_cutout, x))\n",
    "#\n",
    "#"
   ],
   "id": "8169a9501cb9d992",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def cutmix(images, labels, prob=1.0, alpha=1.0):\n",
    "\n",
    "    batch_size = tf.shape(images)[0]\n",
    "    img_h = tf.shape(images)[1]\n",
    "    img_w = tf.shape(images)[2]\n",
    "\n",
    "    do_cutmix = tf.random.uniform([]) < prob\n",
    "    if not do_cutmix:\n",
    "        return images, labels\n",
    "\n",
    "    shuffled_indices = tf.random.shuffle(tf.range(batch_size))\n",
    "    images_shuffled = tf.gather(images, shuffled_indices)\n",
    "    labels_shuffled = tf.gather(labels, shuffled_indices)\n",
    "\n",
    "    lam = tf.compat.v1.distributions.Beta(alpha, alpha).sample()\n",
    "\n",
    "    ratio = tf.sqrt(1.0 - lam)\n",
    "    patch_h = tf.cast(ratio * tf.cast(img_h, tf.float32), dtype=tf.int32)\n",
    "    patch_w = tf.cast(ratio * tf.cast(img_w, tf.float32), dtype=tf.int32)\n",
    "\n",
    "    cy = tf.random.uniform([], maxval=img_h, dtype=tf.int32)\n",
    "    cx = tf.random.uniform([], maxval=img_w, dtype=tf.int32)\n",
    "\n",
    "    y1 = tf.clip_by_value(cy - patch_h // 2, 0, img_h)\n",
    "    y2 = tf.clip_by_value(cy + patch_h // 2, 0, img_h)\n",
    "    x1 = tf.clip_by_value(cx - patch_w // 2, 0, img_w)\n",
    "    x2 = tf.clip_by_value(cx + patch_w // 2, 0, img_w)\n",
    "\n",
    "    patch = tf.ones([y2 - y1, x2 - x1, 1], dtype=tf.float32)\n",
    "\n",
    "    padding = [[y1, img_h - y2], [x1, img_w - x2], [0, 0]]\n",
    "    mask_single = tf.pad(patch, padding, \"CONSTANT\", constant_values=0)\n",
    "\n",
    "    mask = 1.0 - tf.tile(tf.expand_dims(mask_single, 0), [batch_size, 1, 1, 1])\n",
    "\n",
    "    mixed_images = images * mask + images_shuffled * (1.0 - mask)\n",
    "\n",
    "    lam_adjusted = 1.0 - (tf.cast((x2 - x1) * (y2 - y1), tf.float32) / tf.cast(img_h * img_w, tf.float32))\n",
    "    mixed_labels = labels * lam_adjusted + labels_shuffled * (1.0 - lam_adjusted)\n",
    "\n",
    "    return mixed_images, mixed_labels\n",
    "\n",
    "\n",
    "# train_pipeline = (\n",
    "#     train_dataset\n",
    "#     .shuffle(1024)\n",
    "#     .batch(batches)\n",
    "#     .map(lambda img, lbl: cutmix(img, lbl, prob=1.0), num_parallel_calls=autotune)\n",
    "#     .prefetch(autotune)\n",
    "# )\n"
   ],
   "id": "c6dde732941ffc80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Varianta finala prin care am antrenat modelul (nu stiu sigur daca asta a fost structura retelei, dar restul codului ramane la fel)",
   "id": "6e3029375c79a6e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img_h = 100\n",
    "img_w = 100\n",
    "nr_channels = 3\n",
    "nr_classes = 5\n",
    "\n",
    "batches = 32\n",
    "epochs = 100\n",
    "\n",
    "images_train_float32 = images_train.astype('float32')\n",
    "images_validation_float32 = images_validation.astype('float32')\n",
    "\n",
    "labels_train_hot_temp = to_categorical(labels_train, num_classes=nr_classes)\n",
    "labels_validation_hot_temp = to_categorical(labels_validation, num_classes=nr_classes)\n",
    "\n",
    "labels_train_hot = labels_train_hot_temp.astype('float32')\n",
    "labels_validation_hot = labels_validation_hot_temp.astype('float32')\n",
    "\n",
    "\n",
    "retea = models.Sequential([\n",
    "    layers.InputLayer(shape=(img_h, img_w, nr_channels)),\n",
    "    #\n",
    "    # asa se realizeaza apelul la cutout\n",
    "    # layers.Lambda(lambda x: tf.map_fn(custom_cutout, x)),\n",
    "    #\n",
    "    layers.Conv2D(48, (3, 3), padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(48, (3, 3), padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Conv2D(96, (3, 3), padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(96, (3, 3), padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.4),\n",
    "\n",
    "    layers.Conv2D(192, (3, 3), padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(192, (3, 3), padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Conv2D(512, (3, 3), padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(nr_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "retea.summary()\n",
    "\n",
    "retea.compile(optimizer = 'adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath = 'model.keras',\n",
    "    save_weights_only = False,\n",
    "    monitor = 'val_accuracy',\n",
    "    mode = 'max',\n",
    "    save_best_only = True,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "stopping = EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    patience = 15,\n",
    "    verbose = 1,\n",
    "    restore_best_weights = True\n",
    ")\n",
    "\n",
    "reduce_learning = ReduceLROnPlateau(\n",
    "    monitor = 'val_loss',\n",
    "    factor = 0.5,\n",
    "    patience = 7,\n",
    "    verbose = 1,\n",
    "    min_lr = 0.0001\n",
    ")\n",
    "\n",
    "list_of_callbacks = [checkpoint, stopping, reduce_learning]\n",
    "\n",
    "\n",
    "autotune = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((images_train_flat, labels_train_hot))\n",
    "\n",
    "train_pipeline = (\n",
    "    train_dataset\n",
    "    .shuffle(1024)\n",
    "    .batch(batches)\n",
    "    .map(lambda img, lbl: cutmix(img, lbl, prob=1.0), num_parallel_calls=autotune)\n",
    "    .prefetch(autotune)\n",
    ")\n",
    "\n",
    "validation_pipeline = (\n",
    "    tf.data.Dataset.from_tensor_slices((images_validation_flat, labels_validation_hot))\n",
    "    .batch(batches)\n",
    "    .prefetch(autotune)\n",
    ")\n",
    "\n",
    "history = retea.fit(\n",
    "    train_pipeline,\n",
    "    validation_data=validation_pipeline,\n",
    "    epochs=epochs,\n",
    "    callbacks=list_of_callbacks\n",
    ")\n",
    "\n",
    "model_x = models.load_model('model.keras')"
   ],
   "id": "a1ea5c653100c5e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = load_model('model.keras')\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "\n",
    "image_ids = []\n",
    "predicted_labels = []\n",
    "\n",
    "for index, row in df_test.iterrows():\n",
    "    image_name = str(row['image_id'])\n",
    "    image_path = os.path.join('data/test_normalised', image_name + '.npy')\n",
    "\n",
    "    image_array = np.load(image_path)\n",
    "    image_batch = np.expand_dims(image_array, axis=0)\n",
    "\n",
    "    prediction = model.predict(image_batch, verbose=0)\n",
    "    predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "\n",
    "    image_ids.append(image_name)\n",
    "    predicted_labels.append(predicted_class)\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    'image_id': image_ids,\n",
    "    'label': predicted_labels\n",
    "})\n",
    "\n",
    "df_results.to_csv('results.csv', index=False)"
   ],
   "id": "e1de27739b3ff474",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
