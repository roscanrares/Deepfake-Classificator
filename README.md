# Deepfake Classification Project

This repository documents a Deepfake Classification project. This project focuses on classifying AI-generated images. The primary challenge involved gaining a deeper understanding of how AI models generate images and then successfully identify and utilize the unique characteristics introduced during the generation process.

## Table of Contents

* [Introduction](#introduction)
* [Dataset](#dataset)
* [Methodology Highlights](#methodology-highlights)
* [Key Findings](#key-findings)
* [Project Structure](#project-structure)
* [Setup and Installation](#setup-and-installation)
* [Usage](#usage)
* [Author & Coordinator](#author--coordinator)

## Introduction

The project's main goal is to build a model capable of automatically distinguishing between different deepfake images generated by deep neural networks. Throughout the course of this research, I gained a deeper understanding of the potential differences that emerge during AI-based generation.

## Dataset

The project utilizes a generous and labeled dataset from Kaggle, consisting of: 
* **Training images:** 12,500 
* **Validation images:** 1,250 
* **Test images:** 6,500

  
## Methodology Highlights

* **Initial Verifications** Initial checks, including image dimensions, identification and quantification of outliers, and normalization using mean and standard deviation.
* **Initial Experiments:** SVM and Random Forest were explored but yielded unsatisfactory results, struggling to capture necessary features like textures. 
* **Convolutional Neural Networks (CNNs):** CNNs were chosen for their ability to process image data and extract crucial features like textures and artifacts. 
* **Training Improvements:** Implemented `callbacks` (early stopping, learning rate reduction, best model saving) to manage CNN training effectively, and for better results. 
* **Data Augmentation:** Attempts with rotation, zoom, and flip negatively impacted performance. Cutout and CutMix were also explored, with later stages leading to state of the art results. 
* **Color Channels & Other Models:** HSV, LAB color distributions, t-SNE, and XGBoost on color histograms were investigated.  

## Key Findings

* Data augmentation variants (zoom, rotation, flip) hindered performance by removing important image characteristics (whether at 1% or 20%), highlighting the differences between classifying normal images versus AI-generated ones.
* Overfitting was a persistent challenge with CNNs, without data augmentation, it is impossible to achieve >91.5-92% accuracy. 
* Despite searching for artifacts, none were found, and textures appeared similar. Nevertheless, a classic classifier like Random Forest did not achieve more than 70% accuracy.
* Cutout and CutMix proved to be very effective, demonstrating that the 'full image' format was crucial for achieving high accuracy. 

